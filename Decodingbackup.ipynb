{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "378bd66b",
   "metadata": {},
   "source": [
    "Title: Decoding Head-Orientations using MEG\n",
    "\n",
    "Name: Sebastian Montesinos\n",
    "\n",
    "Collaborators: Shruti Japee, Lina Teichmann, and Chris Baker\n",
    "\n",
    "Affiliations: Princeton University, National Institute of Mental Health (NIMH)\n",
    "\n",
    "\n",
    "\n",
    "For this project, I focus on decoding head-orientations within the static conditions. These analyses will be used to assess the baseline capacities of a decoding model trained on static trials, which will be essential for evaluating the success of the models that we eventually use to cross-decode head-orientation in the dynamic trials. \n",
    "\n",
    "\n",
    "Methods:\n",
    "\n",
    "Participants n=20 viewed a total of 16 stimuli of static head-orientations in a randomized, counterbalanced fashion over time. MEG was used to record neural data from 269 sensors as they viewed the stimuli. Each stimulus appeared for a total of 300 miliseconds.\n",
    "\n",
    "Previous analyses:\n",
    "\n",
    "The MEG data has been minimally preprocessed and epoched in a -.2 to .6 second window around stimulus onset. Next, I trained a linear discriminant classifier to decode head-orientation across all 16 conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edc1713",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"First, I  load in the data, extract some useful information, and plot it\"\"\"\n",
    "\n",
    "\n",
    "#Necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.stats import sem\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import os\n",
    "import csv\n",
    "#### INPUT PATHS #####\n",
    "# Define top directory (this is the part of the script someone will need to edit to where they clone the directory to)\n",
    "top_dir = '/Users/sm6511/Desktop/Stats-Project/Stats-503-Final-Project/Final-Project' ##EDIT THIS LINE TO REPRODUCE\n",
    "\n",
    "# This folder contains S01_DecodingAccuracyTimecourse.npy, S02_..., etc. These are the decoding timecourses per subject\n",
    "base_path = os.path.join(top_dir, \"data\")\n",
    "# Where the plots will be saved\n",
    "output_dir = os.path.join(top_dir, \"plots\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "#### CALCULATING MEAN ACCURACY #####\n",
    "#Define a list containing the names for the subjects\n",
    "subjects = [f\"S{i:02}\" for i in range(1, 21)]\n",
    "\n",
    "\n",
    "# Load all accuracy timecourses \n",
    "all_accuracies = []\n",
    "for subj in subjects:\n",
    "    filepath = os.path.join(base_path, f\"{subj}_DecodingAccuracyTimecourse.npy\")\n",
    "    if os.path.exists(filepath):\n",
    "        data = np.load(filepath)\n",
    "        all_accuracies.append(data)\n",
    "    else:\n",
    "        print(f\"Missing: {filepath}\")\n",
    "\n",
    "\n",
    "# Stack the accuracies, compute the mean and the standard error\n",
    "all_accuracies = np.vstack(all_accuracies)\n",
    "mean_acc = all_accuracies.mean(axis=0)\n",
    "sem_acc = sem(all_accuracies, axis=0)\n",
    "\n",
    "# Convert samples to time in seconds (MEG samples at 1200hz, so we have to use this sampling rate to plot in miliseconds)\n",
    "sampling_rate = 1200  # Hz\n",
    "n_timepoints = len(mean_acc)\n",
    "start_time = -0.2  # in seconds\n",
    "end_time = start_time + n_timepoints / sampling_rate\n",
    "time = np.linspace(start_time, end_time, n_timepoints, endpoint=False)\n",
    "\n",
    "#For the cross-decoding analyses, I want to use two representative timepoints for training within the static\n",
    "#To find these two timepoints, I look for the late and early peak in decoding\n",
    "\n",
    "# Find all peaks with at least 10-sample distance\n",
    "peaks, _ = find_peaks(mean_acc, distance=10)\n",
    "\n",
    "# Select the highest peak overall\n",
    "peak1_idx = peaks[np.argmax(mean_acc[peaks])]\n",
    "\n",
    "# Select the highest peak after 0.2 seconds \n",
    "valid_second_peaks = [p for p in peaks if time[p] > 0.2]\n",
    "if not valid_second_peaks:\n",
    "    raise ValueError(\"No second peak found after 0.2 seconds.\")\n",
    "peak2_idx = valid_second_peaks[np.argmax(mean_acc[valid_second_peaks])]\n",
    "\n",
    "# Sort peaks in time\n",
    "final_peaks = np.sort([peak1_idx, peak2_idx])\n",
    "\n",
    "# Compute peaks in miliseconds \n",
    "peak1_sample = int(final_peaks[0])\n",
    "peak2_sample = int(final_peaks[1])\n",
    "peak1_time_ms = round(time[peak1_sample] * 1000, 3)\n",
    "peak2_time_ms = round(time[peak2_sample] * 1000, 3)\n",
    "\n",
    "# Plot Results\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(time, mean_acc, label='Mean Accuracy')\n",
    "plt.axhline(1.0 / 16.0, color='k', linestyle='--', label='Chance')\n",
    "plt.fill_between(time, mean_acc - sem_acc, mean_acc + sem_acc, alpha=0.3, label='Â±1 SEM') #Adds SEM labels\n",
    "\n",
    "# Highlight the two peaks in decoding\n",
    "plt.plot(time[final_peaks], mean_acc[final_peaks], 'ro', label='Top 2 Peaks')\n",
    "for i, p in enumerate(final_peaks, 1):\n",
    "    plt.text(time[p], mean_acc[p] + 0.01, f'Peak {i}', ha='center')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Decoding Accuracy')\n",
    "plt.title('Mean LDA Decoding Accuracy Over Time (16-way Static)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save plot\n",
    "plot_path = os.path.join(output_dir, \"Figure1aMeanDecodingAccuracy.png\")\n",
    "plt.savefig(plot_path, dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62c89c6",
   "metadata": {},
   "source": [
    "Section 1: Loading in the data, extracting some useful information, and plotting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763455fb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Section 2: Looking at every subject's decoding\n",
    "- It's a good idea to see how each subject looks, so I also briefly save out a plot showing the decoding lines for every subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e7a3de",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Visualizing every subject's decoding\"\"\"\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "subjID = 0\n",
    "# Add transparency\n",
    "for subj in all_accuracies:\n",
    "    subjID +=1\n",
    "    smoothed = gaussian_filter1d(subj, sigma=2) ##Added some smoothing to see the difference between subjects\n",
    "    plt.plot(time, smoothed, alpha=0.8, linewidth=1, label=f'Subj {subjID}') \n",
    "\n",
    "# Chance line (1/16)\n",
    "plt.axhline(1/16, color='k', linestyle='--', linewidth=1, alpha=0.7, label='Chance')\n",
    "\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Decoding Accuracy')\n",
    "plt.title('LDA Decoding Accuracy Over Time for all Subjects')\n",
    "plt.grid(True)\n",
    "\n",
    "# Place legend outside so 20 labels don't cover the plot\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"Figure1bAllSubjects_DecodingAccuracy.png\"), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581c24d9",
   "metadata": {},
   "source": [
    "Section 3: Running Statistical tests\n",
    "\n",
    "We now have an initial visualization of the decoding of head-orientations over time. However, in order to assess the model, we must apply some statistics to determine when meaningful information about head-orientation is present. In order to do this, I compute the Bayes Factor across subjects for each timepoint in the trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c7de85",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#Importing in necessary packages to apply BayesFactor\n",
    "import rpy2.robjects as ro\n",
    "import rpy2.robjects.conversion as conversion\n",
    "from rpy2.robjects import pandas2ri, default_converter\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "#Library path to r (MUST BE ADJUSTED IF R IS IN A DIFFERENT ENVIRONMENT!)\n",
    "ro.r('.libPaths(\"/opt/miniconda3/envs/mne2_arm/lib/R/library\")')\n",
    "\n",
    "#Conversion rules\n",
    "conversion.set_conversion(default_converter + pandas2ri.converter)\n",
    "\n",
    "#Import r\n",
    "stringi = importr(\"stringi\")\n",
    "bayesfactor = importr(\"BayesFactor\")\n",
    "\n",
    "print(\" R packages loaded successfully.\") #If this step fails, check where your local R directory is set. This varies by operating system\n",
    "\n",
    "#Parameters for BF analysis\n",
    "\n",
    "chance = 1 / 16 #Chance in this experiment is 1/16, since there are 16 total conditions\n",
    "mu = 0 #Sets the representation for exact chance level performance: I normalize the data by chance in the test\n",
    "nullMin = .5 #WRITE LATER\n",
    "nullMax = float('inf')\n",
    "rscale = 'medium' #WRITE LATER\n",
    "start_time = -0.2  # seconds\n",
    "end_time = 0.6     # seconds\n",
    "\n",
    "# Time vector for plotting\n",
    "times = np.linspace(start_time, end_time, n_timepoints)\n",
    "\n",
    "# Functions\n",
    "\n",
    "def load_subject_scores(decoding_dir):\n",
    "    \"\"\"Load decoding accuracy timecourses for all subjects.\"\"\"\n",
    "    subject_scores = []\n",
    "    subject_ids = []\n",
    "\n",
    "    for file in sorted(os.listdir(decoding_dir)):\n",
    "        if file.endswith(\"_DecodingAccuracyTimecourse.npy\"):\n",
    "            subj_id = file.split(\"_\")[0]\n",
    "            filepath = os.path.join(decoding_dir, file)\n",
    "            scores = np.load(filepath)\n",
    "            subject_scores.append(scores)\n",
    "            subject_ids.append(subj_id)\n",
    "\n",
    "    return np.array(subject_scores), subject_ids\n",
    "\n",
    "def clean_axes(ax):\n",
    "    \"Set the right and top axes to not be visible (this is done because in the final paper this figure will be used)\"\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(True)\n",
    "    ax.spines['bottom'].set_visible(True)\n",
    "    ax.tick_params(direction='out')\n",
    "\n",
    "def compute_bayes_factors_group(data_2d):\n",
    "    \"\"\"Compute the BayesFactor for one person, given their accuracy scores. CHECK LATER\"\"\"\n",
    "\n",
    "    normalized = data_2d - chance #Normalize the data by chance\n",
    "\n",
    "    df = pd.DataFrame(normalized)  # wrap numpy array in pandas DataFrame\n",
    "\n",
    "    bf = []\n",
    "    #Loop over every timepoint in the trial, and compute the BF for that timepoint\n",
    "    for t in range(df.shape[1]):\n",
    "        with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "            # Convert the single column (pandas Series) to R vector\n",
    "            r_vector = ro.conversion.py2rpy(df.iloc[:, t])\n",
    "        #Run the bayesfactor test with the parameters previously specified (running 1 test per timepoint)\n",
    "        result = bayesfactor.ttestBF(\n",
    "            x=r_vector,\n",
    "            mu=mu,\n",
    "            rscale=rscale,\n",
    "            nullInterval=ro.FloatVector([nullMin, nullMax])\n",
    "        )\n",
    "        bf_value = np.array(ro.r['as.vector'](result))[0]\n",
    "        bf.append(bf_value) #add the result of the test to a list\n",
    "\n",
    "    return np.array(bf) \n",
    "\n",
    "\n",
    "def find_latency(bf, times, threshold=6, n_consecutive=5):\n",
    "    \"\"\"Find the first timepoint where n_consecutive points exceed BF threshold.\"\"\"\n",
    "    above_thresh = bf > threshold\n",
    "    # Slide a window of length n_consecutive length to find the first point where all are significant\n",
    "    for i in range(len(above_thresh) - n_consecutive + 1):\n",
    "        if np.all(above_thresh[i:i + n_consecutive]):\n",
    "            latency_time = times[i]\n",
    "            print(latency_time)\n",
    "            print(f\"First sustained decoding (>{threshold}) at {latency_time*1000:.1f} ms\")\n",
    "            return latency_time\n",
    "    print(\"No sustained decoding above threshold found.\")\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_group_results(mean_scores, bf, save_dir, times, data):\n",
    "    \"\"\"Plot mean decoding accuracy and Bayes Factors across timepoints.\"\"\"\n",
    "    \"\"\"Takes in the mean decoding scores, a list of the BFs at each timepoint for those scores, a directory to save the scores, the times in the trial,\"\"\"\n",
    "    \"\"\"and the original non-meaned data (to compute SEM)\"\"\"\n",
    "    print(f\"Length mean_scores: {len(mean_scores)}\")\n",
    "    print(f\"Length bf: {len(bf)}\")\n",
    "\n",
    "    #Create a figure with two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(\n",
    "        2, 1, figsize=(12, 7),\n",
    "        gridspec_kw={'height_ratios': [3, 1]},\n",
    "        sharex=True\n",
    "    )\n",
    "\n",
    "    # Top plot: mean decoding accuracy\n",
    "    sem_scores = data.std(axis=0) / np.sqrt(data.shape[0])\n",
    "    ax1.plot(times, mean_scores*100, color='black')\n",
    "    ax1.fill_between(times, (mean_scores - sem_scores)*100, (mean_scores + sem_scores)*100,\n",
    "                    color='black', alpha=0.2, label='SEM')\n",
    "    ax1.axhline(y=(1/16)*100, color='gray', linestyle='--', label='Chance Level (1/16)', alpha=.7)\n",
    "    ax1.set_ylabel('Decoding Accuracy (%)')\n",
    "    ax1.legend(loc='upper right')\n",
    "\n",
    "    # Bottom plot: Bayes Factor dots\n",
    "    ax2.scatter(times, bf, c=bf, cmap='bwr', norm=LogNorm(vmin=1e-8, vmax=1e8), s=35)\n",
    "\n",
    "    ax2.set_yscale('log')\n",
    "    ax2.set_ylabel('Bayes Factor (BF)')\n",
    "    ax2.axhline(y=1, color='gray', linestyle='--', label='BF = 1', alpha=0.7)\n",
    "    ax2.set_ylim(1e-6, 1e9)\n",
    "    yticks = [1e-6, 1e-3, 1e0, 1e3, 1e6, 1e9]\n",
    "    ax2.set_yticks(yticks)\n",
    "    ax2.set_yticklabels([f\"$10^{{{int(np.log10(t))}}}$\" for t in yticks])\n",
    "    ax2.set_xlabel('Time (s)')\n",
    "\n",
    "    # Colorbar with log scale\n",
    "    sc = ax2.collections[0]  # get the scatter\n",
    "    pos = ax2.get_position()\n",
    "    cbar_ax = fig.add_axes([pos.x1 + 0.01, pos.y0, 0.02, pos.height])\n",
    "    cbar = fig.colorbar(sc, cax=cbar_ax, orientation='vertical')\n",
    "    cbar_ticks = [1e-8, 1e-4, 1e0, 1e4, 1e8]\n",
    "    cbar.set_ticks(cbar_ticks)\n",
    "    cbar.set_ticklabels([f\"$10^{{{int(np.log10(t))}}}$\" for t in cbar_ticks])\n",
    "\n",
    "    bf_lower = 1/6  # BF < 1/6 is moderate evidence for the null\n",
    "    bf_upper = 6    # BF > 6 is moderate evidence for the alternative\n",
    "    ax2.axhspan(bf_lower, bf_upper, color='gray', alpha=0.2, label='Weak Evidence')\n",
    "    ax2.axhline(y=1, color='gray', linestyle='--', alpha=0.7)\n",
    "    clean_axes(ax1)\n",
    "    clean_axes(ax2)\n",
    "    plt.subplots_adjust(hspace=0.05)\n",
    "\n",
    "\n",
    "    fig.suptitle('16-way LDA Decoding Accuracy with BF', fontsize=12, y=.91)\n",
    "    save_path = os.path.join(save_dir, 'Figure1c_Group_Mean_Scores_and_BayesFactors.png')\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "    print(f\"Plot saved to {save_path}\")\n",
    "\n",
    "\n",
    "print(\"Loading subject decoding accuracies...\")\n",
    "data, subject_ids = load_subject_scores(base_path)\n",
    "print(f\"Loaded {len(subject_ids)} subjects with shape {data.shape}\")\n",
    "\n",
    "# Compute group mean and Bayes factors\n",
    "mean_scores = data.mean(axis=0)\n",
    "bf_group = compute_bayes_factors_group(data)\n",
    "\n",
    "# Find latency\n",
    "latency = find_latency(bf_group, times, threshold=6, n_consecutive=5)\n",
    "\n",
    "\n",
    "# Plot results\n",
    "print(\"Plotting group results with Bayes Factor significance..\")\n",
    "plot_group_results(mean_scores, bf_group, output_dir, times, data)\n",
    "print(\"Group plot saved at:\", output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd25b07",
   "metadata": {},
   "source": [
    "The above plot shows decoding over time with a secondary plot showing the results of the BayesFactor test. The purpose of this test is to compare two hypotheses: the null hypothesis (N1), defined as mean decoding accuracy being at chance, and the alternative hypothesis (A1), on which mean decoding accuracy is above chance. The test is one-tailed, as we always expect only at chance or above chance decoding. The BF quantifies how likely we are to observe the data at a timepoint given N1 and A1.\n",
    "\n",
    "We also defined a band where the evidence was 'inconclusive', from a BF of 1/6 to 6, shown in grey above. We picked this as 1/6 is typically considered the threshold for strong evidence for the null, and 6 is typically considered the threshold for strong evidence for the alternative hypothesis. Effect size is set using the nullinterval in a BF test, and previous simulations from our lab have suggested that .5 is typically the best threshold to set for effect size in MEG experiments. \n",
    "\n",
    "Overall, we can see that prior to the presentation of a stimulus, we find strong evidence for the null hypothesis. This result is expected, because the model should be at chance before any stimulus was on the screen. Once the stimulus is presented, the neural latency (the first of five timepoints in a row where we have more than moderate evidence for A1) is 89.2ms. This suggests an estimate for the amount of time it takes before information about face-orientation has had time to process through the visual system in a way detectable by MEG sensors. Evidence for A1 stays about the inconclusive band all the way until .6 seconds, which is .3 seconds after stimulus onset. Therefore, substantial information about head-orientation remains in someone's visual system at least 300ms after the offset of such a stimulus."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
